# -*- coding: utf-8 -*-
"""building-predictive-model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10nNF-1wwpXiczf2hmAuYDb-bp6uI5aZH

## Building Predictive Models
"""

import pandas as pd
import os
import numpy as np

"""### Import Data"""

# set the path of the processed data
processed_data_path = os.path.join(os.path.pardir,'data','processed')
train_file_path = os.path.join(processed_data_path, 'train.csv')
test_file_path = os.path.join(processed_data_path, 'test.csv')

train_df = pd.read_csv(train_file_path, index_col='PassengerId')
test_df = pd.read_csv(test_file_path, index_col='PassengerId')

train_df.info()

test_df.info()

"""### Data Preperation"""

X = train_df.loc[:,'Age':].as_matrix().astype('float')
y = train_df['Survived'].ravel()

print X.shape, y.shape

# train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
print X_train.shape, y_train.shape
print X_test.shape, y_test.shape

# average survival in train and test
print 'mean survival in train : {0:.3f}'.format(np.mean(y_train))
print 'mean survival in test : {0:.3f}'.format(np.mean(y_test))

"""#### Check Scikit-Learn Version"""

import sklearn

sklearn.__version__

"""make sure you have Scikit-Learn v0.19. Else update it and restart kernel. """

#!conda update -y scikit-learn

"""### Baseline Model"""

# import function
from sklearn.dummy import DummyClassifier

# create model
model_dummy = DummyClassifier(strategy='most_frequent', random_state=0)

# train model
model_dummy.fit(X_train, y_train)

print 'score for baseline model : {0:.2f}'.format(model_dummy.score(X_test, y_test))

# peformance metrics
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score

# accuracy score
print 'accuracy for baseline model : {0:.2f}'.format(accuracy_score(y_test, model_dummy.predict(X_test)))

# confusion matrix
print 'confusion matrix for baseline model: \n {0}'.format(confusion_matrix(y_test, model_dummy.predict(X_test)))

# precision and recall scores
print 'precision for baseline model : {0:.2f}'.format(precision_score(y_test, model_dummy.predict(X_test)))
print 'recall for baseline model : {0:.2f}'.format(recall_score(y_test, model_dummy.predict(X_test)))

"""### First Kaggle  Submission """

# converting to the matrix
test_X = test_df.as_matrix().astype('float')

from google.colab import drive
drive.mount('/content/drive')

# get predictions
predictions = model_dummy.predict(test_X)

df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions} )

df_submission.head()

submission_data_path = os.path.join(os.path.pardir,'data','external')
submission_file_path = os.path.join(submission_data_path, '01_dummy.csv')

df_submission.to_csv(submission_file_path, index=False)

def get_submission_file(model, filename):
    # converting to the matrix
    test_X = test_df.as_matrix().astype('float')
    # make predictions
    predictions = model.predict(test_X)
    # submission dataframe
    df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions})
    # submission file
    submission_data_path = os.path.join(os.path.pardir,'data','external')
    submission_file_path = os.path.join(submission_data_path, filename)
    # write to the file
    df_submission.to_csv(submission_file_path, index=False)

# get submission file
get_submission_file(model_dummy, '01_dummy.csv')

"""### Logistic Regression Model"""

# import function
from sklearn.linear_model import LogisticRegression

# create model
model_lr_1 = LogisticRegression(random_state=0)

# train model
model_lr_1.fit(X_train,y_train)

# evaluate model
print 'score for logistic regression - version 1 : {0:.2f}'.format(model_lr_1.score(X_test, y_test))

# performance metrics
# accuracy
print 'accuracy for logistic regression - version 1 : {0:.2f}'.format(accuracy_score(y_test, model_lr_1.predict(X_test)))
# confusion matrix
print 'confusion matrix for logistic regression - version 1: \n {0}'.format(confusion_matrix(y_test, model_lr_1.predict(X_test)))
# precision 
print 'precision for logistic regression - version 1 : {0:.2f}'.format(precision_score(y_test, model_lr_1.predict(X_test)))
# precision 
print 'recall for logistic regression - version 1 : {0:.2f}'.format(recall_score(y_test, model_lr_1.predict(X_test)))

# model coefficients
model_lr_1.coef_

"""### Second Kaggle Submission"""

# get submission file
get_submission_file(model_lr_1, '02_lr.csv')



















"""### Part 2

### Hyperparameter Optimization
"""

# base model 
model_lr = LogisticRegression(random_state=0)

from sklearn.model_selection import GridSearchCV

parameters = {'C':[1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1','l2']}
clf = GridSearchCV(model_lr, param_grid=parameters, cv=3)

clf.fit(X_train, y_train)

clf.best_params_

print 'best score : {0:.2f}'.format(clf.best_score_)

# evaluate model
print 'score for logistic regression - version 2 : {0:.2f}'.format(clf.score(X_test, y_test))

"""### Making Third Submission"""

# get submission file
get_submission_file(clf, '03_lr.csv')

"""### Feature Normalization and Standardization"""

from sklearn.preprocessing import MinMaxScaler, StandardScaler

"""#### Feature Normalization"""

# feature normalization
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)

X_train_scaled[:,0].min(),X_train_scaled[:,0].max()

# normalize test data
X_test_scaled = scaler.transform(X_test)

"""#### Feature Standardization"""

# feature standardization
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""#### Create model after standardization"""

# base model 
model_lr = LogisticRegression(random_state=0)
parameters = {'C':[1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1','l2']}
clf = GridSearchCV(model_lr, param_grid=parameters, cv=3)
clf.fit(X_train_scaled, y_train)

clf.best_score_

# evaluate model
print 'score for logistic regression - version 2 : {0:.2f}'.format(clf.score(X_test_scaled, y_test))

"""### Model Persistence"""

# import pickle library
import pickle

# create the file paths
model_file_path = os.path.join(os.path.pardir,'models','lr_model.pkl')
scaler_file_path = os.path.join(os.path.pardir,'models','lr_scaler.pkl')

# open the files to write 
model_file_pickle = open(model_file_path, 'wb')
scaler_file_pickle = open(scaler_file_path, 'wb')

# persist the model and scaler
pickle.dump(clf, model_file_pickle)
pickle.dump(scaler, scaler_file_pickle)

# close the file
model_file_pickle.close()
scaler_file_pickle.close()

"""#### load the persisted file"""

# open files in read mode
model_file_pickle = open(model_file_path, 'r')
scaler_file_pickle = open(scaler_file_path, 'r')
# load files
clf_loaded = pickle.load(model_file_pickle)
scaler_loaded = pickle.load(scaler_file_pickle)
# close files
model_file_pickle.close()
scaler_file_pickle.close()

clf_loaded

scaler_loaded

# transform the test data using loaded scaler object
X_test_scaled = scaler_loaded.transform(X_test)
# calculate the score using loaded model object 
print 'score for persisted logistic regression : {0:.2f}'.format(clf_loaded.score(X_test_scaled, y_test))









"""### Third Kaggle Submission"""

def get_submission_file_with_standardization(model,filename, scaler):
    # converting to the matrix
    test_X = test_df.as_matrix().astype('float')
    # standardization
    test_X = scaler.transform(test_X)
    # make predictions
    predictions = model.predict(test_X)
    # submission dataframe
    df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions})
    # submission file
    submission_data_path = os.path.join(os.path.pardir,'data','external')
    submission_file_path = os.path.join(submission_data_path, filename)
    # write to the file
    df_submission.to_csv(submission_file_path, index=False)

# get submission file
get_submission_file_with_standardization(clf, '04_lr.csv', scaler)

"""### Random Forest Model"""

from sklearn.ensemble import RandomForestClassifier

model_rf_1 = RandomForestClassifier(random_state=0)
model_rf_1.fit(X_train_scaled, y_train)

# evaluate model
print 'score for random forest - version 1 : {0:.2f}'.format(model_rf_1.score(X_test_scaled, y_test))

# get submission file
get_submission_file_with_standardization(model_rf_1, '04_rf.csv', scaler)

"""### HyperParameter Tuning"""

from sklearn.model_selection import GridSearchCV

parameters = {'n_estimators':[10, 100, 200], 
              'min_samples_leaf':[1, 5,10,50],
              'max_features' : ('auto','sqrt','log2'),
               }
rf = RandomForestClassifier(random_state=0, oob_score=True)
clf = GridSearchCV(rf, parameters)

clf.fit(X_train, y_train)

clf.best_estimator_

# best score
print 'best score for random forest : {0:.2f}'.format(clf.best_score_)

# get submission file
get_submission_file(clf, '05_rf.csv')

"""### Confusion Metrics , Precision and Recall"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

model.fit(X_train, y_train)

from sklearn import metrics

model.score(X_test, y_test)

pred = model.predict(X_test)
fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)
metrics.auc(fpr, tpr)

# Predict on Final Test data

test_X = test_df.as_matrix().astype('float')

test_X = scaler.transform(test_X)

predictions = model.predict_proba(test_X)

print predictions.shape

